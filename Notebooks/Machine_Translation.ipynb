{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6d9Dy3pmeaJS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IyNyTJaZk46P",
        "outputId": "8fd1d577-1f71-4773-9994-10000a7d98da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    english_sentence  \\\n",
              "0  politicians do not have permission to do what ...   \n",
              "1         I'd like to tell you about one such child,   \n",
              "2  This percentage is even greater than the perce...   \n",
              "3  what we really mean is that they're bad at not...   \n",
              "4  .The ending portion of these Vedas is called U...   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
              "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(r'C:\\Users\\Shaikh Irfan\\Documents\\Ai Adeventures\\Machine Translation\\data\\Hindi_English_Truncated_Corpus.csv')\n",
        "data.drop('source',axis=1,inplace=True)\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KLbie113VGq5"
      },
      "outputs": [],
      "source": [
        "input_sentences, target_sentences = zip(*data.values)\n",
        "# input_sentences, target_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IrgXo-tmVRWd"
      },
      "outputs": [],
      "source": [
        "def build_vocab(data):\n",
        "  words = set(\" \".join(map(str, data)).split())\n",
        "  words_to_idx = {word:idx for idx,word in enumerate(words)}\n",
        "  idx_to_words = {idx:word for word,idx in words_to_idx.items()}\n",
        "  return words_to_idx,idx_to_words,len(words)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pbSuIbbtWHkJ"
      },
      "outputs": [],
      "source": [
        "input_vocab, input_idx_to_word, input_vocab_size = build_vocab(input_sentences)\n",
        "target_vocab, target_idx_to_word, target_vocab_size = build_vocab(target_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fo-PcUQzXqOV"
      },
      "outputs": [],
      "source": [
        "def encode_sentences(sentence,vocab):\n",
        "  return [vocab.get(words,0) for words in str(sentence).split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uM52xhNfbMi4"
      },
      "outputs": [],
      "source": [
        "input_encoded = [encode_sentences(sentence,input_vocab) for sentence in input_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o6VaJhbHbpz-"
      },
      "outputs": [],
      "source": [
        "target_encoded = [encode_sentences(sentence,target_vocab) for sentence in target_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9tL_riTicQSk"
      },
      "outputs": [],
      "source": [
        "max_input_len = max(len(seq) for seq in input_encoded)\n",
        "max_target_len = max(len(seq) for seq in target_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XV149yR5dDFT"
      },
      "outputs": [],
      "source": [
        "input_encoded = [seq + [0]* (max_input_len - len(seq)) for seq in input_encoded]\n",
        "target_encoded = [seq + [0]* (max_target_len - len(seq))for seq in target_encoded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q-Q61TDUdnMa"
      },
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "dataset = TranslationDataset(input_encoded, target_encoded)\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_SqKIRHreY3q"
      },
      "outputs": [],
      "source": [
        "# Define Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, (hidden, cell) = self.lstm(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "# Define Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        output = self.fc(output)\n",
        "        return output, hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NRD_A5YxgmzY"
      },
      "outputs": [],
      "source": [
        "# Define Seq2Seq Model\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        hidden, cell = self.encoder(src)\n",
        "        outputs = []\n",
        "        input = tgt[:, 0].unsqueeze(1)  # Start with the first word\n",
        "\n",
        "        for t in range(1, tgt.size(1)):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs.append(output)\n",
        "            input = tgt[:, t].unsqueeze(1)  # Teacher forcing\n",
        "\n",
        "        return torch.cat(outputs, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jIjpygfrg6Ip"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 10\n",
        "hidden_dim = 20\n",
        "n_epochs = 5\n",
        "\n",
        "# Initialize models\n",
        "encoder = Encoder(input_vocab_size, embedding_dim, hidden_dim)\n",
        "decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLNb8oIhhawn"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "epoch_times = []\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "        loss = criterion(output.view(-1, target_vocab_size), tgt[:, 1:].contiguous().view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_duration = end_time - start_time\n",
        "    epoch_times.append(epoch_duration)\n",
        "    \n",
        "    avg_time = sum(epoch_times) / len(epoch_times)\n",
        "    epochs_left = n_epochs - (epoch + 1)\n",
        "    est_remaining = avg_time * epochs_left\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{n_epochs} took {epoch_duration:.2f} seconds.\")\n",
        "    print(f\"Estimated time remaining: {est_remaining/60:.2f} minutes\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "datFy7O6h3qx"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "    model.eval()\n",
        "    encoded_input = encode_sentences(sentence, input_vocab)\n",
        "    input_tensor = torch.tensor(encoded_input + [0] * (max_input_len - len(encoded_input)), dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(input_tensor)\n",
        "        tgt = torch.zeros(1, max_target_len, dtype=torch.long)  # Placeholder for the target\n",
        "        tgt[0, 0] = list(input_vocab.items())[0][1] # start with the first word of target_vocab\n",
        "\n",
        "        for t in range(1, max_target_len):\n",
        "            output, hidden, cell = model.decoder(tgt[:, t-1].unsqueeze(1), hidden, cell)\n",
        "            predicted_idx = output.argmax(2)[:, -1]\n",
        "            tgt[0, t] = predicted_idx\n",
        "            if predicted_idx.item() == 0:  # Stop if we hit padding\n",
        "                break\n",
        "\n",
        "    return ' '.join(target_idx_to_word[idx.item()] for idx in tgt[0] if idx.item() != 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZSDABOUiFcN"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_sentence = \"see you later\"\n",
        "translated_sentence = translate(test_sentence)\n",
        "print(f'Translation of \"{test_sentence}\": \"{translated_sentence}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNVtmLneiLUH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
